{
    "componentChunkName": "component---src-templates-content-js",
    "path": "/howWeBuiltAnEisPlatformPart1IngestionOfData",
    "result": {"pageContext":{"title":"How we built an EIS Platform - Part1 : Ingestion of Data","tags":["AWS","Data Lake","Migration","Architecture"],"publishedOn":"12/31/2021","location":"howWeBuiltAnEisPlatformPart1IngestionOfData","repo":"blogs","content":"<p>We helped build an <em>Enterprise Information Dashboard</em> that aggregated data across its tenants and helped them power a dashboard helping them with a unified data visibility.\nIn this first part of the blog, where I talk about the path we took to move the data into the data lake. We'll look into how it was transformed and presented in the next part.   </p>\n<h2 id=\"tldr\"><a href=\"#tldr\">TL;DR</a></h2>\n<p>Data that was spread across 120+ DB instances ( tenant specific sharding ) was pulled into AWS Redshift into <em>Staging Tables</em>.\nWe were able to achieve the same using AWS DMS, writing configurations using its JSON transformation rules.</p>\n<h2 id=\"current-system-and-problem-statement\"><a href=\"#current-system-and-problem-statement\">Current System and Problem Statement</a></h2>\n<p>Our client provides whitelabel solution of a financial product with over 120+ customers(tenants). They had their data sharded and isolated at a tenant level, with different DB instance per customer.\nDepending on the functionality, they also had the data split across databases, viz. lookup DB, transaction DB, customer DB etc. On top of this, some customers were available across regions ( IN, SG, NA etc. ). For each of these regions, the tenants had a separate DB instance as well.</p>\n<p>The schema across these different DB instances were different in most cases. To address quickly changing customer needs, each tenant's tables could have more or less fields, or additional tables.\nStandardization of data through <strong>One Script</strong> is not going to work in our case.  </p>\n<p>With these requirements in mind, we split this overall problem statement into 3 major groups.</p>\n<ul>\n<li>Ingestion </li>\n<li>Conversion </li>\n<li>Presentation</li>\n</ul>\n<p>We also had to consider, as part of the solution</p>\n<ul>\n<li>Ease of on-boarding a new tenant</li>\n<li>Ability to customize the dashboard</li>\n<li>Familiarity of technology for in-house devs for future enhancements and maintenance</li>\n<li>Role Based Access Control</li>\n<li>AWS as the platform</li>\n</ul>\n<h2 id=\"redshift-for-data-lake\"><a href=\"#redshift-for-data-lake\">Redshift for Data Lake</a></h2>\n<p>As mentioned earlier, familiarity of technology was an important factor while coming up with overall solution.\nSo we put our initial effort into identifying the technology to be used for building the data lake first. </p>\n<p>We had many options but chose <a href=\"https://aws.amazon.com/redshift/\">AWS Redshift</a> as our choice as </p>\n<ul>\n<li>Familiar interface based on SQL  </li>\n<li>Low or no learning curve</li>\n<li>AWS based solution </li>\n<li>Performant queries with proper sort and distribution key</li>\n</ul>\n<h2 id=\"ingestion\"><a href=\"#ingestion\">Ingestion</a></h2>\n<p>Data ingestion required a one time import of existing data as well as ongoing sync of data.\nThis required identification of changes, and propagating them to the Data lake platform. </p>\n<p>We can achieve the same through </p>\n<ul>\n<li>Intrusive techniques - viz. changing the code to push the data to the Data lake</li>\n<li>Non-Intrusive techniques - viz. looking into DB changes and replicating the same into the Data lake</li>\n</ul>\n<p>The intrusive technique was easiest and cheapest way to push the data, but it involved </p>\n<ul>\n<li>Changes to existing code</li>\n<li>Handling of logic across different languages ( Java, Go and Python, which were already in use )</li>\n<li>Documentation and setting up process, to ensure future code changes do not miss the sync. </li>\n<li>DDL changes will require manual handling at the data lake end as well to propagate the changes.</li>\n<li>Coordination, testing, and deployment of many services across tenants</li>\n</ul>\n<p>This was risky and increased the time to market, thus making us adopt a non-intrusive technique for data replication. </p>\n<p>While looking into Non-Intrusive techniques, we had 2 possible ways of handling the same</p>\n<ul>\n<li>Poll the database at regular intervals, and pull incremental data from the tables</li>\n<li>Look for changes in Binary Logs or OpLogs and replay them</li>\n</ul>\n<h2 id=\"poll-and-pull\"><a href=\"#poll-and-pull\">Poll and Pull</a></h2>\n<p><img src=\"./images/DataAggregatorAndEIS/pollandpull.svg\" alt=\"Poll and Pull\"></p>\n<p>This method involved writing a script that would pull the data in regular intervals from each of the tables of the DB and push them to a data stream.\nA script per DB can be implemented and the data can be produced by many such services. These stream of data changes will be consumed by a downstream application,\nthat would be responsible for pushing the data changes to Redshift. </p>\n<p>As a general rule, we will only pull the \"Delta\" and not the full data as it will have performance ramifications. Identification of the Delta would happen based on available Audit Columns.\nThe last processed date from the audit column would be made a note of and would be used as the reference for next pulls. </p>\n<p>We found this to be a desirable approach as</p>\n<ul>\n<li>The scripts can be per DB, which means we can do the transformation as part of the pull operation</li>\n<li>In case of pull system crashing, the restart can be quite simple to handle, as we can catchup from where we left last</li>\n<li>The frequency of pull can be changed and controlled per DB basis as well depending on the growth of data</li>\n<li>Simple design in comparison to other non-intrusive techniques </li>\n<li>Querying against read-replica of the DB will ensure primary DB is not impacted</li>\n</ul>\n<p>BUT we were unable to adopt this technique due to one major issue. *Not all tables had proper <strong>Audit Columns*</strong>.\nFinding delta through any other technique would be contrived and error-prone. </p>\n<h2 id=\"observing-binary-log-changes\"><a href=\"#observing-binary-log-changes\">Observing Binary Log Changes</a></h2>\n<p><img src=\"./images/DataAggregatorAndEIS/bin-log-observer.svg\" alt=\"Binlog Observer\"></p>\n<p>The database as an audit mechanism will log every change that goes into it. These can be both DML or DDL statements, that can add/modify data or structure.\nWhen logged using a \"ROW level logging\" format, every change is captured as part of the binary logs.</p>\n<p>We wanted to build a service that would look for changes in the bin-log and would be able to use this information to replicate the data into Redshift.\nThis service should</p>\n<ul>\n<li>Automatically restart in case of crash ( like a systemd process )</li>\n<li>Log from where it left last time in case of restarts</li>\n<li>Binary log retention policy of DB to be setup appropriately to ensure the process would well and at the same time not impact DB</li>\n<li>For failures spanning beyond more than the retention time, a strategy to capture delta needed to be worked out.</li>\n<li>Handle identification and propagation of DDL changes automatically to Redshift.</li>\n</ul>\n<p>Rather than reinventing the wheel, we looked at leveraging existing solutions.</p>\n<h2 id=\"debezium\"><a href=\"#debezium\">Debezium</a></h2>\n<p><a href=\"https://debezium.io/\">Debezium</a> is an opensource platform that captures data changes and streams them into a KAFKA topic.\nIt looks into the binary log of the database and throws events of every change that occurs in the DB. </p>\n<p>Every change is emitted as json that indicates the nature of operation ( Insert, update or delete ), along with timestamp, and before and after change states.\nThese are published as events in a KAFKA topic which can then be consumed and used to push data into Redshift. Debezium has connectors for popular Databases as well which makes development effort to be close to nothing.</p>\n<p><img src=\"./images/DataAggregatorAndEIS/debezium.svg\" alt=\"Debezium Flow\"></p>\n<p>But Debezium came with a complex infra setup which included KAFKA, a service that keeps running the Debezium server and consumer, which requires additional monitoring in place.\nWe also had to think about the strategy to move the initial data to redshift and in case of long failures, a strategy to identify delta and load them. </p>\n<p>The time to market and ease of maintenance was critical for us, and we started looking into other options.</p>\n<h2 id=\"aws-dms\"><a href=\"#aws-dms\">AWS DMS</a></h2>\n<p><a href=\"https://aws.amazon.com/dms/\">AWS Data Migration Service</a> provides what Debezium does along with </p>\n<ul>\n<li>Data sync in case of first time or delta</li>\n<li>Self-managed services hiding all complexities of how data is moved from DB to Redshift</li>\n<li>First class support for DB hosted in RDS and Redshift.</li>\n</ul>\n<p>This ticked all the right boxes for us, and we pursued the same.</p>\n<p>DMS provides a tool called the <a href=\"https://aws.amazon.com/dms/schema-conversion-tool\">Schema Conversion Tool</a> that can be installed in your computer.\nYou open the tool, provide the details on source DB and the destination to which it needs to be migrated to.\nThe tool connects to the source, identifies all the DB objects and comes up with a report on whether of not a direct migration is possible.\nFortunately for us the migration was straight forward as DB specific features were not used.</p>\n<p>For DMS to work a few DB level settings are required</p>\n<ul>\n<li><strong>binlog_format</strong> should be set to <strong>ROW</strong></li>\n<li><strong>read_only</strong> flag to be set to <strong>0</strong> for allowing write access</li>\n<li><strong>log_bin_trust_function_creators</strong> should be set to <strong>1</strong> to allow DMS to get triggers for every data change in binary log</li>\n</ul>\n<p>Instead of making these changes in the primary DB, we made these in the read replicas, so that there won't be any undesirable impact. </p>\n<p>Finally, the process of data migration involves </p>\n<ul>\n<li>Creating a Data collector which spins up an instance</li>\n<li>Adding an endpoint for source and destination DB</li>\n<li>Adding a task to the Data collector for each of the source DBs with the destination to be same redshift. </li>\n</ul>\n<p>This would also require an additional S3 bucket that would be used to temporarily store data during migration. </p>\n<p>While creating the task, you can provide specific schema names to be created while moving the data. We used this to differentiate the various source Databases in our staging tables.\nThis would mean that we will have to add <em>transformation rule</em> that would map tables to the destination. </p>\n<p>Though there is a handy wizard that helps you to achieve the same, doing it repeatedly for individual tables of each DB, belonging to each functionality, tenant and region would become too tedious. </p>\n<p>This is where we used the <strong>JSON transformation rules</strong> instead of the wizard. Our configurations were repeated in nature, and we wrote a small\nUI screen which asks for the Region, DB and functionality details along with list of tables, and generates a JSON that can be copied and pasted into the DMS console while creating the task. </p>\n<h2 id=\"data-format\"><a href=\"#data-format\">Data format</a></h2>\n<p>With DMS working fine for us, we wanted to plan how we will import the data into Redshift. </p>\n<p>As already mentioned earlier, we needed to import data from tenants, across regions and functionalities.\nWe created a schema per DB in redshift, and named the schema with a <strong>TENANT_REGION_FUNCTION</strong> format. This way data from each of the DB were created inside its own schema. </p>\n<p>A task is created per schema in Redshift which brought the data from the source. The data pulled into each of these schemas were just an exact replica of what was in its production DB.\nThis means that the tables across these schemas may or may not be same. Since we separated it based on schemas the issue with different data formats were not a concern and DMS was able to do its job without any complications. </p>\n<p><img src=\"./images/DataAggregatorAndEIS/data-format-mapping.svg\" alt=\"Data format Mapping\"></p>\n<h2 id=\"next\"><a href=\"#next\">Next</a></h2>\n<p>In the next blog, I'll talk about how the different tables in different schemas were made into a common format and transformed into facts and dimensions. We'll also discuss the platform that was built to help the client onboard with ease.</p>","pagePath":"blogs","owner":"arunmadhavan-g","file":"DataAggregationAndEIS.md"}},
    "staticQueryHashes": ["3649515864"]}